##### 细节配置 #####

logger:
  wandb_group: ""
  wandb_name: ""
  wandb_project: Fengshen-HumanFeedback
  wandb_team: null

defaults:
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-05
  learning_rate: 1.0e-06
  min_learning_rate: 1.0e-07
  lr_decay_ratio: 1.0
  lr_decay_steps: 0
  warmup_max_lr: 0.0001
  warmup_min_lr: 1.0e-09
  warmup_ratio: 0.01
  warmup_steps: 0
  weight_decay: 0.1
  scheduler_type: cosine

megatron:
  deepspeed_stage: 2
  offload_optimizer: true
  policy_precision: bf16
  rm_precision: fp16
  tensor_model_parallel_size: 4
  pipe_model_parallel_size: 1
  seed: 42
  gradient_accumulation_steps: 8

data:
  dataset_path: null
  workspace_path: null
  prefix: 
    model: "<bot>:"
    human: "<human>:"
  multiturn_seperator: "\n"  

policy_model:
  policy_model_type: "llama_13B"
  policy_tokenizer_path: null
  policy_model_path: null
  policy_max_seq_len: 1900

reward_model:
  reward_model_type: "llama_13B"
  rm_tokenizer_path: null
  reward_model_path: null
  rm_max_seq_len: 2048
  granularity: "token"

generation:
  top_k: 0
  top_p: 0.85
  temperature: 1.0
  repetition_penalty: 1.0
  max_new_tokens: 1024

ppo:
  experience:
    experience_batch_size: 128
    generate_minibatch_size: 32
    policy_minibatch_size: 8
    rm_minibatch_size: 2
    sample_batch_size: 128
    buffer_limit_size: 512
    replay_buffer_cpu_offload: true
    sample_replay_buffer: false
  ppo_details:
    eps_clip: 0.2
    value_clip: 0.2
    gamma: 0.99
    lam: 0.95
    enable_gae: true
    enable_step_level: false
    enable_token_level_loss: true
    enable_reward_scaling: true
    enable_token_reward: true
  ppopp_details:
    ppopp_beta: 0.5
    ppopp_beta_decay: 1.0
    ppopp_rate: 0.9
    ppopp_rate_decay: 0.98
    use_guide_action: false
  trainer:
    num_workers: 2
    num_episodes: 512
    total_steps: 512
    max_timesteps: 1
    update_timesteps: 1
    actor_lr: 2.0e-06
    critic_lr: 1.0e-05
    max_epoch_per_update: 2
    policy_train_batch_size: 2
    clip_grad: true
    kl_coef: 0.0
    entropy_loss_coef: 0.01
    entropy_loss_decay_rate: 1.0
    do_validation: true
    val_every_n_episode: 5
    val_size_per_task: 16

