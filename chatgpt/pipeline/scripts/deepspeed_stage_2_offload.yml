##### 分布式训练配置 #####

megatron:
  deepspeed_stage: 2
  offload_optimizer: true
  policy_precision: bf16
  rm_precision: fp16
  seed: 42
  gradient_accumulation_steps: 8
  enable_hybrid_engine: false
